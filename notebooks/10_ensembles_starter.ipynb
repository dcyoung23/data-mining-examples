{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d1af48-f75f-4153-8ee0-e23cd349a2e2",
   "metadata": {},
   "source": [
    "# Combining Methods: Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b2ed2-9a4a-44b3-8267-6506fc0476e0",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a3d8a0-663c-450a-9c3a-d8b47fcf0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer, fbeta_score\n",
    "import statsmodels.api as sm \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from dmba import classificationSummary, gainsChart, liftChart \n",
    "\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23738a-e242-4aae-8b7a-c0f5c661be36",
   "metadata": {},
   "source": [
    "# Problem 13.1: Acceptance of Consumer Loan\n",
    "\n",
    "Universal Bank has begun a program to encourage its existing customers to borrow via a consumer loan program.  The bank has promoted the loan to 5000 customers, of whom 480 accepted the offer. The data are available in file __UniversalBank.csv__. The bank now wants to develop a model to predict which customers have the greatest probability of accepting the loan, to reduce promotion costs and send the offer only to a subset of its customers. \n",
    "\n",
    "We will develop several models, then combine them in an ensemble. The models we will use are \n",
    "1. logistic regression, \n",
    "2. $k$-nearest neighbors with $k=3$, and \n",
    "3. classification trees\n",
    "4. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a25e2-f57a-48ed-adb2-a2c8fbdc94e5",
   "metadata": {},
   "source": [
    "**Create a dataframe for the `UniversalBank.csv` data**\n",
    "\n",
    "- Bin the following variables so they can be used in Naive Bayes:\n",
    "  - Age (5 bins)\n",
    "  - Experience (10 bins)\n",
    "  - Income (5 bins)\n",
    "  - CC Average (6 bins)\n",
    "  - Mortgage (10 bins)\n",
    "- Education and Family can be used as is, without binning\n",
    "- ID and Zip code can be ignored\n",
    "- Use one-hot-encoding to convert the categorical data into indicator variables\n",
    "- Partition the data: 60% training, 40% validation.\n",
    "\n",
    "<h4 style=\"color:blue\"> Write Your Code Below: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a730e2-3264-468b-8079-3f55a6d655ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df = pd.read_csv(os.path.join('..', 'data', 'UniversalBank.csv'))\n",
    "# Drop ID and zip code columns\n",
    "bank_df.drop(columns=['ID', 'ZIP Code'], inplace=True)\n",
    "bank_df.columns = [c.replace(' ','_') for c in bank_df.columns]\n",
    "\n",
    "bank_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb7237-eee8-4f64-bb38-9dd6056e5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert continuous variables into bins\n",
    "bank_df['Age'] = pd.cut(bank_df['Age'], 5, labels=range(1, 6)).astype('category')\n",
    "bank_df['Experience'] = pd.cut(bank_df['Experience'], 10, labels=range(1, 11)).astype('category')\n",
    "bank_df['Income'] = pd.cut(bank_df['Income'], 5, labels=range(1, 6)).astype('category')\n",
    "bank_df['CCAvg'] = pd.cut(bank_df['CCAvg'], 6, labels=range(1, 7)).astype('category')\n",
    "bank_df['Mortgage'] = pd.cut(bank_df['Mortgage'], 10, labels=range(1, 11)).astype('category')\n",
    "\n",
    "# Use one-hot-encoding for the categorical variables\n",
    "bank_df = pd.get_dummies(bank_df, prefix_sep='_')\n",
    "\n",
    "X = bank_df.drop(columns=['Personal_Loan'])\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "y = bank_df['Personal_Loan']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=SEED)\n",
    "print('Training set:', X_train.shape, 'Test set:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a776d064-fd26-4ff2-9960-bd6cec0657b8",
   "metadata": {},
   "source": [
    "<h3 style=\"color:teal\"> Expected Output: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfede0dd-1d5b-4e15-a5a8-e385ad73c5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Age                 5000 non-null   int64  \n",
      " 1   Experience          5000 non-null   int64  \n",
      " 2   Income              5000 non-null   int64  \n",
      " 3   Family              5000 non-null   int64  \n",
      " 4   CCAvg               5000 non-null   float64\n",
      " 5   Education           5000 non-null   int64  \n",
      " 6   Mortgage            5000 non-null   int64  \n",
      " 7   Personal_Loan       5000 non-null   int64  \n",
      " 8   Securities_Account  5000 non-null   int64  \n",
      " 9   CD_Account          5000 non-null   int64  \n",
      " 10  Online              5000 non-null   int64  \n",
      " 11  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 468.9 KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "107f812b-8ed2-47ee-ac1b-78d030b560ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (3000, 42) Test set: (2000, 42)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c45e4bb2-104a-4ec9-b3cd-73dffa62b815",
   "metadata": {},
   "source": [
    "### 13.1.a\n",
    "\n",
    "Fit models to the data for \n",
    "1. logistic regression, \n",
    "2. $k$-nearest neighbors with $k=3$, \n",
    "3. classification trees, and \n",
    "4. Naive Bayes. \n",
    "\n",
    "Use Personal Loan as the outcome variable.  Report the validation confusion matrix for each of the models.\n",
    "\n",
    "<h4 style=\"color:blue\"> Write Your Code Below: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3ffa3-61a0-4a91-a393-9bedae9f42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "\n",
    "classificationSummary(y_test, logit_reg.predict(X_test))\n",
    "\n",
    "# k-nearest neighbors\n",
    "\n",
    "classificationSummary(y_test, knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb6e4f-78da-4ac1-8263-5ba66027639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification tree\n",
    "# user grid search to find optimized tree\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, 25], \n",
    "    'min_impurity_decrease': [0, 0.001, 0.005, 0.01], \n",
    "    'min_samples_split': [10, 20, 30, 40, 50], \n",
    "}\n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(random_state=SEED), param_grid, cv=5, n_jobs=-1)\n",
    "gridSearch.fit(X_train, y_train)\n",
    "print('Initial parameters: ', gridSearch.best_params_)\n",
    "\n",
    "# Run 2nd grid search here\n",
    "\n",
    "\n",
    "print('Improved parameters: ', gridSearch.best_params_)\n",
    "\n",
    "dt = gridSearch.best_estimator_\n",
    "\n",
    "classificationSummary(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361c90a-23ec-4c8e-81a1-1c5f37f8b156",
   "metadata": {},
   "source": [
    "<h3 style=\"color:teal\"> Expected Output: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23de4b8c-2b0d-4fc6-8b03-af3254598ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.9490)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1773   34\n",
      "     1   68  125\n",
      "Confusion Matrix (Accuracy 0.9350)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1796   11\n",
      "     1  119   74\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db410259-d8f9-470a-a7f9-05f691e4c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters:  {'max_depth': 10, 'min_impurity_decrease': 0.001, 'min_samples_split': 10}\n",
      "Improved parameters:  {'max_depth': 7, 'min_impurity_decrease': 0, 'min_samples_split': 15}\n",
      "Confusion Matrix (Accuracy 0.9670)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1789   18\n",
      "     1   48  145\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "917099fb-0c73-440e-b59b-2bef90535f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.8860)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1657  150\n",
      "     1   78  115\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes\n",
    "nb = MultinomialNB(alpha=0.01)\n",
    "nb.fit(X_train, y_train)\n",
    "classificationSummary(y_test, nb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e71976-2b80-4ebb-8549-eeef2de443db",
   "metadata": {},
   "source": [
    "### 13.1.b/c\n",
    "Create a data frame with the actual outcome, predicted probabilities/outcome for each of the models. Display the first 10 rows.\n",
    "\n",
    "<h4 style=\"color:blue\"> Write Your Code Below: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05edd4f5-1e60-4dd6-8f3a-69c74e2543cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "    'actual': y_test,\n",
    "    'log_reg_prob': logit_reg.predict_proba(X_test)[:, 1],\n",
    "    'log_reg_pred': logit_reg.predict(X_test),\n",
    "    'knn_prob': knn.predict_proba(X_test)[:, 1],\n",
    "    'knn_pred': knn.predict(X_test),\n",
    "    'dt_prob': dt.predict_proba(X_test)[:, 1],\n",
    "    'dt_pred': dt.predict(X_test),\n",
    "    'nb_prob': nb.predict_proba(X_test)[:, 1],\n",
    "    'nb_pred': nb.predict(X_test),\n",
    "})\n",
    "\n",
    "pred_cols = ['log_reg_pred', \n",
    "             'knn_pred', \n",
    "             'dt_pred', \n",
    "             'nb_pred']\n",
    "\n",
    "# Calculate voting majority\n",
    "\n",
    "prob_cols = ['log_reg_prob', \n",
    "             'knn_prob', \n",
    "             'dt_prob', \n",
    "             'nb_prob']\n",
    "\n",
    "# Calculate average probability and prediction\n",
    "\n",
    "\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906aa5f-b0c9-4b1f-9465-9eb07b7a9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Majority vote')\n",
    "classificationSummary(result['actual'], result['majority'])\n",
    "\n",
    "print('Average probability')\n",
    "classificationSummary(result['actual'], result['average_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48255d84-1c0a-4c6d-aceb-5b09fbbf40ca",
   "metadata": {},
   "source": [
    "<h3 style=\"color:teal\"> Expected Output: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f9edaa-e9c0-478a-958c-94e1577ed1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>log_reg_prob</th>\n",
       "      <th>log_reg_pred</th>\n",
       "      <th>knn_prob</th>\n",
       "      <th>knn_pred</th>\n",
       "      <th>dt_prob</th>\n",
       "      <th>dt_pred</th>\n",
       "      <th>nb_prob</th>\n",
       "      <th>nb_pred</th>\n",
       "      <th>majority</th>\n",
       "      <th>average</th>\n",
       "      <th>average_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>0</td>\n",
       "      <td>1.906725e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.572781e-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>0</td>\n",
       "      <td>1.346563e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.846322e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>0</td>\n",
       "      <td>3.912990e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.143519e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>0</td>\n",
       "      <td>1.116179e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.452705e-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>0</td>\n",
       "      <td>2.816480e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.897707e-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>0</td>\n",
       "      <td>4.139157e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.439887e-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>0</td>\n",
       "      <td>1.161518e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.749560e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>0</td>\n",
       "      <td>2.154792e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.418332e-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0</td>\n",
       "      <td>6.325349e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572092</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.844900e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0</td>\n",
       "      <td>7.034610e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.672648</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.286426e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  log_reg_prob  log_reg_pred  knn_prob  knn_pred   dt_prob  \\\n",
       "2764       0  1.906725e-03             0  0.000000         0  0.000000   \n",
       "4767       0  1.346563e-07             0  0.000000         0  0.000000   \n",
       "3814       0  3.912990e-07             0  0.000000         0  0.000000   \n",
       "3499       0  1.116179e-02             0  0.000000         0  0.000000   \n",
       "2735       0  2.816480e-03             0  0.000000         0  0.007463   \n",
       "3922       0  4.139157e-06             0  0.000000         0  0.000000   \n",
       "2701       0  1.161518e-03             0  0.000000         0  0.000000   \n",
       "1179       0  2.154792e-01             0  0.000000         0  0.270833   \n",
       "932        0  6.325349e-01             1  0.333333         0  0.800000   \n",
       "792        0  7.034610e-01             1  0.666667         1  0.871795   \n",
       "\n",
       "      dt_pred   nb_prob  nb_pred  majority       average  average_pred  \n",
       "2764        0  0.004384        0         0  1.572781e-03             0  \n",
       "4767        0  0.000001        0         0  2.846322e-07             0  \n",
       "3814        0  0.000002        0         0  6.143519e-07             0  \n",
       "3499        0  0.126946        0         0  3.452705e-02             0  \n",
       "2735        0  0.005312        0         0  3.897707e-03             0  \n",
       "3922        0  0.000002        0         0  1.439887e-06             0  \n",
       "2701        0  0.002338        0         0  8.749560e-04             0  \n",
       "1179        0  0.081020        0         0  1.418332e-01             0  \n",
       "932         1  0.572092        1         1  5.844900e-01             1  \n",
       "792         1  0.672648        1         1  7.286426e-01             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d13b3b3-af4f-41a9-b224-3b4ee6ae018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority vote\n",
      "Confusion Matrix (Accuracy 0.9495)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1797   10\n",
      "     1   91  102\n",
      "Average probability\n",
      "Confusion Matrix (Accuracy 0.9595)\n",
      "\n",
      "       Prediction\n",
      "Actual    0    1\n",
      "     0 1796   11\n",
      "     1   70  123\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d1fc168-852f-4c94-8800-72f1613f9390",
   "metadata": {},
   "source": [
    "### 13.1.d\n",
    "\n",
    "Compare the error rates for the four individual methods and the two ensemble methods.\n",
    "\n",
    "<h4 style=\"color:blue\"> Write Your Code Below: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969485e-abcb-4b21-9c2d-ab760d97d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'Logistic regression': 'log_reg_pred', \n",
    "          'k-Nearest Neighbor': 'knn_pred', \n",
    "          'Decision Tree': 'dt_pred', \n",
    "          'Naive Bayes': 'nb_pred',\n",
    "          'Majority Vote': 'majority',\n",
    "          'Average Probability': 'average_pred'}\n",
    "error_rates = []\n",
    "\n",
    "# Loop through dict and append error rates\n",
    "\n",
    "\n",
    "pd.DataFrame(error_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80bea1-9acc-4fe7-b522-e71d379c5821",
   "metadata": {},
   "source": [
    "<h3 style=\"color:teal\"> Expected Output: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "536e277e-8b77-4a43-84c8-f8102c1a1d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Error Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k-Nearest Neighbor</td>\n",
       "      <td>0.9350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.8860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Majority Vote</td>\n",
       "      <td>0.9495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Probability</td>\n",
       "      <td>0.9595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Error Rate\n",
       "0  Logistic regression      0.9490\n",
       "1   k-Nearest Neighbor      0.9350\n",
       "2        Decision Tree      0.9670\n",
       "3          Naive Bayes      0.8860\n",
       "4        Majority Vote      0.9495\n",
       "5  Average Probability      0.9595"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e55760d7-d24c-4c3c-8ad2-6f63d13d3986",
   "metadata": {},
   "source": [
    "**Use F2 Score as a Custom Evaluation Metric**\n",
    "\n",
    "In this dataset, using `accuracy_score` as your evaluation metric may not be appropriate due to the class imbalance — only about 10% of customers have previously accepted the personal loan offer. \n",
    "\n",
    "While precision and recall provide helpful insights, we often want a single metric that balances both. The **F1 Score** does this by giving equal weight to precision and recall. However, in situations like this — where *missing positives* (False Negatives) is more costly than False Positives — the **F2 Score** is a better choice because it gives more importance to recall.\n",
    "\n",
    "### Important Note:\n",
    "> In `sklearn`, the F2 Score (`fbeta_score` with `beta=2`) is *not* directly available as a built-in scoring option for tools like `cross_val_score` or `GridSearchCV`. To use it, you’ll need to create a custom scoring function.\n",
    "\n",
    "**Create Two Examples of Custom F2 Scorers:**\n",
    "- Example 1: Using `fbeta_score` directly with `make_scorer`\n",
    "- Example 2: Writing your own custom scoring function to calculate the F2 score\n",
    "\n",
    "\n",
    "Use both of your custom scorers to calculate and display the F2 Score for your Decision Tree model from earlier.\n",
    "\n",
    "<h4 style=\"color:blue\"> Write Your Code Below: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d61029-6a9d-4bb9-8471-fb14476cb56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to calculate F2 Score manually\n",
    "\n",
    "\n",
    "# Show how to use make_scorer using fbeta_score directly\n",
    "\n",
    "\n",
    "dt_pred = dt.predict(X_test)\n",
    "\n",
    "print(f'Decision Tree Accuracy: {accuracy_score(y_test, dt_pred):.2%}')\n",
    "print(f'Decision Tree F2 Score: {custom_f2_score(y_test, dt_pred):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf30ad-3e7e-4089-b73c-0baba651e5ab",
   "metadata": {},
   "source": [
    "<h3 style=\"color:teal\"> Expected Output: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aa16f70-7ed8-45cc-8216-69267118a145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 96.70%\n",
      "Decision Tree F2 Score: 77.54%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8874ca66-532e-4083-a9ad-ca51d1bb38a2",
   "metadata": {},
   "source": [
    "**Using VotingClassifier for Hard and Soft Voting**\n",
    "\n",
    "Previously, we manually combined predictions from multiple models using majority vote and average probabilities. Instead of doing this manually, we can simplify the process by using `VotingClassifier` from `sklearn` — an ensemble learning method that automatically handles hard and soft voting.\n",
    "\n",
    "1. Recreate your ensemble from earlier using `VotingClassifier` in two different ways:\n",
    "   - Hard Voting → `voting='hard'` (majority rule based on predicted class labels)\n",
    "   - Soft Voting → `voting='soft'` (based on the average of predicted probabilities)\n",
    "\n",
    "2. For each version (hard and soft voting), display the following evaluation metrics:\n",
    "   - `accuracy_score`\n",
    "   - `F2 Score` (using your custom scorer from the previous step)\n",
    "\n",
    "<h4 style=\"color:blue\"> Write Your Code Below: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3dbb2f-2804-4bae-add5-c44feea9a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VotingClassifier for hard\n",
    "\n",
    "\n",
    "vc_hard_pred = vc_hard.predict(X_test)\n",
    "\n",
    "print(f'Voting Classifier Hard Vote Accuracy: {accuracy_score(y_test, vc_hard_pred):.2%}')\n",
    "print(f'Voting Classifier Hard Vote F2 Score: {custom_f2_score(y_test, vc_hard_pred):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21211b55-0e14-4d8c-9576-c0c28e0f7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create VotingClassifier for soft\n",
    "\n",
    "\n",
    "vc_soft_pred = vc_soft.predict(X_test)\n",
    "\n",
    "print(f'Voting Classifier Soft Vote Accuracy: {accuracy_score(y_test, vc_soft_pred):.2%}')\n",
    "print(f'Voting Classifier Soft Vote F2 Score: {custom_f2_score(y_test, vc_soft_pred):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d76517-ad3a-4695-8b9b-efa1a1cbd82b",
   "metadata": {},
   "source": [
    "<h3 style=\"color:teal\"> Expected Output: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab96bc24-d5c5-44ef-ad7a-4f88ecdfafea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Hard Vote Accuracy: 94.95%\n",
      "Voting Classifier Hard Vote F2 Score: 57.69%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "effdb993-17ac-4c5d-a707-6de1543143b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Soft Vote Accuracy: 95.95%\n",
      "Voting Classifier Soft Vote F2 Score: 67.88%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "430efad0-0b4e-485d-a4fb-987071effb00",
   "metadata": {},
   "source": [
    "**Train a Meta-Learner for Stacking**\n",
    "\n",
    "In this step, you will create a *meta-learner* to combine the predictions from the base models.\n",
    "\n",
    "- Train a simple `LogisticRegression` model using the *training predictions* generated from your base models as the input features.\n",
    "\n",
    "> *Reminder:* The meta-learner is trained on the outputs of your base models — not the original dataset — and will learn how to best combine those predictions to make the final classification.\n",
    "\n",
    "<h4 style=\"color:blue\"> Write Your Code Below: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867a882-eac5-423e-9448-3b1ca85ada20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for model predictions\n",
    "\n",
    "\n",
    "X = train_result[pred_cols]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "logit_reg2 = sm.Logit(y_train, X).fit()\n",
    "\n",
    "logit_reg2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84f330-814a-4e3a-a345-b254ec615e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions on test\n",
    "\n",
    "\n",
    "logit_reg2_pred = (logit_reg2.predict(X_test2) > 0.50).astype(int)\n",
    "\n",
    "print(f'Stacked Logistic Regression Accuracy: {accuracy_score(y_test, logit_reg2_pred):.2%}')\n",
    "print(f'Stacked Logistic Regression F2 Score: {custom_f2_score(y_test, logit_reg2_pred):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c9597-d3e1-4549-ba38-8d9975c947c5",
   "metadata": {},
   "source": [
    "<h3 style=\"color:teal\"> Expected Output: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d6209ad-a23e-48b5-98bc-058df0bdf09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.074166\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Personal_Loan</td>  <th>  No. Observations:  </th>  <td>  3000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  2995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 13 Apr 2025</td> <th>  Pseudo R-squ.:     </th>  <td>0.7649</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:59:41</td>     <th>  Log-Likelihood:    </th> <td> -222.50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -946.37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   -4.3962</td> <td>    0.175</td> <td>  -25.145</td> <td> 0.000</td> <td>   -4.739</td> <td>   -4.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_reg_pred</th> <td>    2.4442</td> <td>    0.500</td> <td>    4.892</td> <td> 0.000</td> <td>    1.465</td> <td>    3.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>knn_pred</th>     <td>    5.1360</td> <td>    0.627</td> <td>    8.192</td> <td> 0.000</td> <td>    3.907</td> <td>    6.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dt_pred</th>      <td>    5.1535</td> <td>    0.400</td> <td>   12.883</td> <td> 0.000</td> <td>    4.369</td> <td>    5.937</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nb_pred</th>      <td>   -0.2656</td> <td>    0.477</td> <td>   -0.557</td> <td> 0.578</td> <td>   -1.201</td> <td>    0.670</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &  Personal\\_Loan  & \\textbf{  No. Observations:  } &     3000    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &     2995    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        4    \\\\\n",
       "\\textbf{Date:}            & Sun, 13 Apr 2025 & \\textbf{  Pseudo R-squ.:     } &   0.7649    \\\\\n",
       "\\textbf{Time:}            &     20:59:41     & \\textbf{  Log-Likelihood:    } &   -222.50   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -946.37   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } &    0.000    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                        & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}          &      -4.3962  &        0.175     &   -25.145  &         0.000        &       -4.739    &       -4.054     \\\\\n",
       "\\textbf{log\\_reg\\_pred} &       2.4442  &        0.500     &     4.892  &         0.000        &        1.465    &        3.423     \\\\\n",
       "\\textbf{knn\\_pred}      &       5.1360  &        0.627     &     8.192  &         0.000        &        3.907    &        6.365     \\\\\n",
       "\\textbf{dt\\_pred}       &       5.1535  &        0.400     &    12.883  &         0.000        &        4.369    &        5.937     \\\\\n",
       "\\textbf{nb\\_pred}       &      -0.2656  &        0.477     &    -0.557  &         0.578        &       -1.201    &        0.670     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:          Personal_Loan   No. Observations:                 3000\n",
       "Model:                          Logit   Df Residuals:                     2995\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Sun, 13 Apr 2025   Pseudo R-squ.:                  0.7649\n",
       "Time:                        20:59:41   Log-Likelihood:                -222.50\n",
       "converged:                       True   LL-Null:                       -946.37\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           -4.3962      0.175    -25.145      0.000      -4.739      -4.054\n",
       "log_reg_pred     2.4442      0.500      4.892      0.000       1.465       3.423\n",
       "knn_pred         5.1360      0.627      8.192      0.000       3.907       6.365\n",
       "dt_pred          5.1535      0.400     12.883      0.000       4.369       5.937\n",
       "nb_pred         -0.2656      0.477     -0.557      0.578      -1.201       0.670\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f998e2c-ae09-4af0-9d0d-eb2e7dadcf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Logistic Regression Accuracy: 96.65%\n",
      "Stacked Logistic Regression F2 Score: 79.28%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "297c5b58-6363-4922-99c3-9e7c1eeffb61",
   "metadata": {},
   "source": [
    "**Use `StackingClassifier` Instead**\n",
    "\n",
    "Instead of manually generating and combining predictions from your base models, you can simplify the process by using `sklearn`'s built-in `StackingClassifier`.\n",
    "\n",
    "- Recreate your stacked model using `StackingClassifier` to automatically handle combining your base models and training the meta-learner.  \n",
    "- Use the same base models and meta-learner from your previous stacking example.\n",
    "\n",
    "After fitting your `StackingClassifier`, display the following performance metrics on the test set:\n",
    "- `accuracy_score`\n",
    "- F2 Score (using your custom F2 scorer)\n",
    "\n",
    "> 🎯 *Tip:* This approach saves time and ensures consistent evaluation without needing to manually generate training and test predictions from each base model.\n",
    "\n",
    "<h4 style=\"color:blue\"> Write Your Code Below: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97e3e4-b5c9-49e0-9eb3-92414cab3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StackingClassifier\n",
    "\n",
    "\n",
    "sc_pred = sc.predict(X_test)\n",
    "\n",
    "print(f'Stacking Classifier Accuracy: {accuracy_score(y_test, sc_pred):.2%}')\n",
    "print(f'Stacking Classifier F2 Score: {custom_f2_score(y_test, sc_pred):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c40e0-2100-482f-bd82-34b73eab561a",
   "metadata": {},
   "source": [
    "<h3 style=\"color:teal\"> Expected Output: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe32ac9-efff-4250-ad4d-815c3d1b434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 96.95%\n",
      "Stacking Classifier F2 Score: 77.96%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01914d56-0f39-460e-9e6c-8196b5d63387",
   "metadata": {},
   "source": [
    "**Tune an AdaBoost Model Using the Custom F2 Scorer**\n",
    "\n",
    "In this step, you will tune an `AdaBoostClassifier` using `GridSearchCV` and your custom F2 scoring function from earlier.\n",
    "\n",
    "---\n",
    "\n",
    "### Parameter Grid to Search:\n",
    "\n",
    "Use the following parameters for your grid search:\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0, 10.0],\n",
    "    'estimator__max_depth': [1, 3, 5]\n",
    "}\n",
    "```\n",
    "\n",
    "> *Note:* The `estimator__max_depth` parameter controls the depth of the base decision tree used within AdaBoost.\n",
    "\n",
    "1. Perform a grid search using `GridSearchCV` with:\n",
    "   - The parameter grid above  \n",
    "   - 5-fold cross-validation  \n",
    "   - Your custom F2 scorer  \n",
    "\n",
    "2. Display:\n",
    "   - The best parameter combination  \n",
    "   - The best F2 Score from cross-validation  \n",
    "\n",
    "<h4 style=\"color:blue\"> Write Your Code Below: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a359778-174a-4584-bb15-cffeefddd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Base weak learner decision tree\n",
    "\n",
    "# Define AdaBoost Classifier\n",
    "\n",
    "# Parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0, 10.0],\n",
    "    'estimator__max_depth': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Grid Search with 5-fold CV\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(f'Best AdaBoost Parameters:\" {grid_search.best_params_}')\n",
    "# Best score\n",
    "print(f'Best AdaBoost Grid Search Score: {np.mean(grid_search.best_score_):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b02f6-3170-4544-b444-d7870181298f",
   "metadata": {},
   "source": [
    "<h3 style=\"color:teal\"> Expected Output: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a7fefd1-919f-4c35-82e9-6d14529bc0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Parameters:\" {'estimator__max_depth': 5, 'learning_rate': 1.0, 'n_estimators': 100}\n",
      "Best AdaBoost Grid Search Score: 87.00%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7860281c-d20b-4842-b00b-532583d16c2d",
   "metadata": {},
   "source": [
    "**Demonstrate Cross-Validation using the Custom Scorer**\n",
    "\n",
    "<h4 style=\"color:blue\"> Write Your Code Below: </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a08cb-7270-4232-af3e-3d8402267a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator2 = DecisionTreeClassifier(max_depth=5, random_state=SEED)\n",
    "\n",
    "ada2 = AdaBoostClassifier(estimator=base_estimator2, learning_rate=1.0, n_estimators=100, random_state=SEED).fit(X_train, y_train)\n",
    "\n",
    "# Run cross_val_score using custom scorer\n",
    "\n",
    "\n",
    "print(f'AdaBoost Cross Validation Scores: {np.mean(ada_scores):.2%}')\n",
    "\n",
    "ada_pred = ada2.predict(X_test)\n",
    "print(f'AdaBoost Accuracy: {accuracy_score(y_test, ada_pred):.2%}')\n",
    "print(f'AdaBoost F2 Score: {custom_f2_score(y_test, ada_pred):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14506d53-b737-4184-9512-54aa59068c2c",
   "metadata": {},
   "source": [
    "<h3 style=\"color:teal\"> Expected Output: </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52826fc5-e7bd-43bb-b835-2402984f3015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBost Cross Validation Scores: 87.00%\n",
      "AdaBoost Accuracy: 96.75%\n",
      "AdaBoost F2 Score: 81.24%\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
